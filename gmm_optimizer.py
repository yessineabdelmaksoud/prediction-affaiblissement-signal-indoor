import numpy as np
from sklearn.mixture import GaussianMixture
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist
from pathloss_calculator import PathlossCalculator
from image_processor import ImageProcessor

class GMMOptimizer:
    """
    Optimiseur utilisant Gaussian Mixture Model (GMM) avec algorithme EM
    pour le placement de points d'acc√®s WiFi.
    
    Avantages par rapport √† K-means:
    - Peut capturer des clusters de formes ellipso√Ødales
    - Mod√©lise la variance de chaque cluster
    - Donne des probabilit√©s d'appartenance 
    - Meilleure adaptation aux zones de formes irr√©guli√®res
    """
    
    def __init__(self, frequency=2.4e9, covariance_type='diag', max_iter=100, random_state=42):
        """
        Initialise l'optimiseur GMM.
        
        Args:
            frequency: Fr√©quence de transmission en Hz
            covariance_type: Type de covariance ('diag', 'full', 'tied', 'spherical')
                           'diag' recommand√© pour efficacit√©
            max_iter: Nombre maximal d'it√©rations EM
            random_state: Graine al√©atoire pour reproductibilit√©
        """
        self.frequency = frequency
        self.frequency_mhz = frequency / 1e6  # Conversion Hz vers MHz
        self.covariance_type = covariance_type
        self.max_iter = max_iter
        self.random_state = random_state
        self.pathloss_calculator = PathlossCalculator(self.frequency_mhz)
        self.processor = ImageProcessor()
        
    def optimize_clustering_gmm(self, coverage_points, grid_info, longueur, largeur,
                               target_coverage_db=-70.0, min_coverage_percent=90.0,
                               power_tx=20.0, max_access_points=6):
        """
        Optimise le placement des points d'acc√®s avec GMM + EM.
        
        Args:
            coverage_points: Points √† couvrir [(x, y), ...]
            grid_info: Informations sur la grille
            longueur, largeur: Dimensions
            target_coverage_db: Signal minimal requis
            min_coverage_percent: Couverture minimale
            power_tx: Puissance de transmission
            max_access_points: Nombre maximal de points d'acc√®s
            
        Returns:
            best_config: Meilleure configuration trouv√©e
            gmm_analysis: Analyse des mod√®les GMM
        """
        if len(coverage_points) == 0:
            return {'access_points': [], 'score': 0.0, 'stats': {}}, {}
        
        # Conversion en array numpy
        points_array = np.array(coverage_points)
        
        best_config = None
        best_score = -1.0
        gmm_analysis = {}
        
        # Test diff√©rents nombres de composantes (points d'acc√®s)
        max_components = min(max_access_points, len(coverage_points), 8)
        print(f"GMM+EM: test de 1 √† {max_components} composantes (objectif {min_coverage_percent}%)")
        
        for n_components in range(1, max_components + 1):
            try:
                # Cr√©ation et ajustement du mod√®le GMM
                gmm = GaussianMixture(
                    n_components=n_components,
                    covariance_type=self.covariance_type,
                    max_iter=self.max_iter,
                    random_state=self.random_state,
                    init_params='kmeans'  # Initialisation avec K-means pour stabilit√©
                )
                
                # Ajustement du mod√®le (algorithme EM)
                gmm.fit(points_array)
                
                # Pr√©diction des labels et probabilit√©s
                labels = gmm.predict(points_array)
                probabilities = gmm.predict_proba(points_array)
                
                # Extraction des centres (moyennes des gaussiennes)
                centers = gmm.means_
                
                # Ajustement des centres pour √©viter les murs
                adjusted_centers = []
                for i, center in enumerate(centers):
                    x, y = center
                    
                    # V√©rification si dans un mur
                    x_pixel = int(np.clip(x / grid_info['scale_x'], 0, grid_info['walls_detected'].shape[1] - 1))
                    y_pixel = int(np.clip(y / grid_info['scale_y'], 0, grid_info['walls_detected'].shape[0] - 1))
                    
                    # Si dans un mur, utiliser le point pond√©r√© le plus proche
                    if grid_info['walls_detected'][y_pixel, x_pixel] > 0:
                        # Trouver les points du cluster avec leurs probabilit√©s
                        cluster_points = points_array[labels == i]
                        cluster_probs = probabilities[labels == i, i]
                        
                        if len(cluster_points) > 0:
                            # Moyenne pond√©r√©e par les probabilit√©s
                            weights = cluster_probs / np.sum(cluster_probs)
                            x = np.average(cluster_points[:, 0], weights=weights)
                            y = np.average(cluster_points[:, 1], weights=weights)
                            
                            # Re-v√©rification si toujours dans un mur
                            x_pixel = int(np.clip(x / grid_info['scale_x'], 0, grid_info['walls_detected'].shape[1] - 1))
                            y_pixel = int(np.clip(y / grid_info['scale_y'], 0, grid_info['walls_detected'].shape[0] - 1))
                            
                            if grid_info['walls_detected'][y_pixel, x_pixel] > 0:
                                # Utiliser le centro√Øde simple si la moyenne pond√©r√©e √©choue
                                x, y = np.mean(cluster_points, axis=0)
                    
                    adjusted_centers.append((x, y, power_tx))
                
                # Calcul des m√©triques de qualit√© GMM
                aic = gmm.aic(points_array)
                bic = gmm.bic(points_array)
                log_likelihood = gmm.score(points_array)
                
                # √âvaluation de la configuration avec le calculateur de couverture
                # (Cette partie d√©pend de votre calculate_coverage_quality_2d existant)
                score, stats = self._evaluate_configuration(
                    adjusted_centers, coverage_points, grid_info,
                    target_coverage_db, min_coverage_percent
                )
                
                # Stockage des informations d'analyse
                gmm_analysis[n_components] = {
                    'centers': adjusted_centers,
                    'score': score,
                    'stats': stats,
                    'labels': labels,
                    'probabilities': probabilities,
                    'covariances': gmm.covariances_,
                    'weights': gmm.weights_,
                    'aic': aic,
                    'bic': bic,
                    'log_likelihood': log_likelihood,
                    'converged': gmm.converged_,
                    'n_iter': gmm.n_iter_
                }
                
                # Mise √† jour du meilleur score
                if score > best_score:
                    best_score = score
                    best_config = {
                        'access_points': adjusted_centers,
                        'score': score,
                        'stats': stats,
                        'n_components': n_components,
                        'algorithm': 'GMM+EM',
                        'gmm_metrics': {
                            'aic': aic,
                            'bic': bic,
                            'log_likelihood': log_likelihood,
                            'converged': gmm.converged_
                        }
                    }
                
                # Arr√™t anticip√© si objectif atteint
                current_coverage = stats.get('coverage_percent', 0.0)
                covered_points = stats.get('covered_points', 0)
                total_points = stats.get('total_points', len(coverage_points))
                
                print(f"üìä GMM {n_components} composantes: {current_coverage:.1f}% de couverture ({covered_points}/{total_points} points)")
                
                # Si objectif atteint, s'arr√™ter imm√©diatement avec cette configuration
                if current_coverage >= min_coverage_percent:
                    print(f"‚úÖ Objectif {min_coverage_percent}% atteint avec {n_components} composantes - ARR√äT OPTIMISATION")
                    
                    # Cette configuration respecte l'objectif, on s'arr√™te ici
                    best_config = {
                        'access_points': adjusted_centers,
                        'score': score,
                        'stats': stats,
                        'n_components': n_components,
                        'algorithm': 'GMM+EM',
                        'early_stop': True,
                        'early_stop_reason': f"Objectif {min_coverage_percent}% atteint",
                        'gmm_metrics': {
                            'aic': aic,
                            'bic': bic,
                            'log_likelihood': log_likelihood,
                            'converged': gmm.converged_
                        }
                    }
                    break  # Sortir de la boucle imm√©diatement
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur GMM avec {n_components} composantes: {e}")
                continue
        
        # Affichage final uniforme
        if best_config:
            print(f"‚úÖ Optimisation GMM termin√©e:")
            print(f"   - Algorithme: GMM + EM")
            print(f"   - {len(best_config['access_points'])} points d'acc√®s plac√©s")
            final_coverage = best_config['stats']['coverage_percent']
            covered = best_config['stats']['covered_points']
            total = best_config['stats']['total_points']
            print(f"   - {final_coverage:.1f}% de couverture ({covered}/{total} points)")
            print(f"   - Score: {best_config['score']:.3f}")
            print(f"   - Convergence: {best_config.get('gmm_metrics', {}).get('converged', 'Unknown')}")
            
            # Indiquer si arr√™t anticip√©
            if best_config.get('early_stop', False):
                reason = best_config.get('early_stop_reason', 'Objectif atteint')
                print(f"   - Arr√™t anticip√©: {reason}")
                print(f"   - Optimisation efficace: minimum de composantes pour l'objectif")
            else:
                print(f"   - Optimisation compl√®te: meilleur score global selon AIC/BIC")
        else:
            print("‚ùå Aucune configuration GMM trouv√©e")
        
        return best_config, gmm_analysis
    
    def _evaluate_configuration(self, access_points, coverage_points, grid_info,
                               target_coverage_db, min_coverage_percent):
        """
        √âvalue une configuration de points d'acc√®s en utilisant le m√™me calculateur que les autres algorithmes.
        """
        covered_points = 0
        total_points = len(coverage_points)
        signal_levels = []
        
        for point in coverage_points:
            x_rx, y_rx = point
            best_signal = -200.0
            
            for ap in access_points:
                x_tx, y_tx, power_tx = ap
                
                # Distance 2D
                distance_2d = np.sqrt((x_rx - x_tx)**2 + (y_rx - y_tx)**2)
                
                if distance_2d < 0.1:  # Tr√®s proche
                    received_power = power_tx - 10
                else:
                    # Conversion en pixels pour comptage des murs
                    x_tx_pixel = int(np.clip(x_tx / grid_info['scale_x'], 0, grid_info['walls_detected'].shape[1] - 1))
                    y_tx_pixel = int(np.clip(y_tx / grid_info['scale_y'], 0, grid_info['walls_detected'].shape[0] - 1))
                    x_rx_pixel = int(np.clip(x_rx / grid_info['scale_x'], 0, grid_info['walls_detected'].shape[1] - 1))
                    y_rx_pixel = int(np.clip(y_rx / grid_info['scale_y'], 0, grid_info['walls_detected'].shape[0] - 1))
                    
                    # Comptage des murs
                    wall_count = self.processor.count_walls_between_points(
                        grid_info['walls_detected'],
                        (x_tx_pixel, y_tx_pixel),
                        (x_rx_pixel, y_rx_pixel)
                    )
                    
                    # Calcul du pathloss unifi√©
                    pathloss = self.pathloss_calculator.calculate_pathloss(distance_2d, wall_count)
                    received_power = power_tx - pathloss
                
                if received_power > best_signal:
                    best_signal = received_power
            
            signal_levels.append(best_signal)
            if best_signal >= target_coverage_db:
                covered_points += 1
        
        coverage_percent = (covered_points / total_points) * 100 if total_points > 0 else 0.0
        
        # Score avec p√©nalit√© pour trop de points d'acc√®s
        num_aps = len(access_points)
        coverage_score = coverage_percent / 100.0
        efficiency_penalty = num_aps * 0.05
        score = coverage_score - efficiency_penalty
        
        if coverage_percent >= min_coverage_percent:
            score += 0.5
        
        stats = {
            'covered_points': covered_points,
            'total_points': total_points,
            'coverage_percent': coverage_percent,
            'signal_levels': signal_levels,
            'num_access_points': num_aps
        }
        
        return max(score, 0.0), stats
    
    def visualize_gmm_clusters(self, points_array, gmm_analysis, best_n_components, 
                              longueur, largeur, image_array=None):
        """
        Visualise les clusters GMM et leurs ellipses de confiance.
        
        Args:
            points_array: Points de couverture
            gmm_analysis: Analyse des mod√®les GMM
            best_n_components: Nombre optimal de composantes
            longueur, largeur: Dimensions
            image_array: Image de fond optionnelle
            
        Returns:
            fig: Figure matplotlib
        """
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        if best_n_components in gmm_analysis:
            analysis = gmm_analysis[best_n_components]
            centers = analysis['centers']
            labels = analysis['labels']
            covariances = analysis['covariances']
            
            # Graphique 1: Clusters avec ellipses de confiance
            if image_array is not None:
                ax1.imshow(image_array, extent=[0, longueur, largeur, 0], cmap='gray', alpha=0.7)
            
            # Points color√©s par cluster
            scatter = ax1.scatter(points_array[:, 0], points_array[:, 1], 
                                c=labels, cmap='tab10', alpha=0.6, s=20)
            
            # Centres des clusters
            for i, (x, y, power) in enumerate(centers):
                ax1.scatter(x, y, c='red', s=200, marker='*', 
                          edgecolors='black', linewidth=2)
                ax1.annotate(f'AP{i+1}', (x, y), xytext=(5, 5), 
                           textcoords='offset points', fontweight='bold')
                
                # Ellipse de confiance am√©lior√©e
                if self.covariance_type == 'diag' and i < len(covariances):
                    std_x = np.sqrt(covariances[i][0])
                    std_y = np.sqrt(covariances[i][1])
                    
                    # Ellipse plus r√©aliste avec vraie ellipse au lieu de cercle
                    from matplotlib.patches import Ellipse
                    ellipse = Ellipse((x, y), width=4*std_x, height=4*std_y, 
                                    fill=False, color='red', alpha=0.5, linestyle='--')
                    ax1.add_patch(ellipse)
                elif self.covariance_type == 'full' and i < len(covariances):
                    # Pour covariance compl√®te, calculer les axes principaux
                    cov = covariances[i]
                    eigenvals, eigenvecs = np.linalg.eigh(cov)
                    angle = np.degrees(np.arctan2(eigenvecs[1, 0], eigenvecs[0, 0]))
                    width, height = 4 * np.sqrt(eigenvals)
                    
                    from matplotlib.patches import Ellipse
                    ellipse = Ellipse((x, y), width=width, height=height, angle=angle,
                                    fill=False, color='red', alpha=0.5, linestyle='--')
                    ax1.add_patch(ellipse)
                else:
                    # Fallback: cercle simple
                    circle = plt.Circle((x, y), 5.0, fill=False, color='red', alpha=0.5, linestyle='--')
                    ax1.add_patch(circle)
            
            ax1.set_xlim(0, longueur)
            ax1.set_ylim(largeur, 0)
            ax1.set_xlabel('Longueur (m)')
            ax1.set_ylabel('Largeur (m)')
            ax1.set_title(f'Clusters GMM - {best_n_components} composantes')
            ax1.grid(True, alpha=0.3)
            
            # Graphique 2: M√©triques de s√©lection de mod√®le
            n_components_list = list(gmm_analysis.keys())
            aic_values = [gmm_analysis[n]['aic'] for n in n_components_list]
            bic_values = [gmm_analysis[n]['bic'] for n in n_components_list]
            scores = [gmm_analysis[n]['score'] for n in n_components_list]
            
            ax2_twin = ax2.twinx()
            
            line1 = ax2.plot(n_components_list, aic_values, 'b-o', label='AIC', linewidth=2)
            line2 = ax2.plot(n_components_list, bic_values, 'g-s', label='BIC', linewidth=2)
            line3 = ax2_twin.plot(n_components_list, scores, 'r-^', label='Score Couverture', linewidth=2, color='red')
            
            ax2.axvline(x=best_n_components, color='black', linestyle='--', alpha=0.7, label='Optimal')
            
            ax2.set_xlabel('Nombre de Composantes')
            ax2.set_ylabel('AIC / BIC', color='blue')
            ax2_twin.set_ylabel('Score de Couverture', color='red')
            ax2.set_title('S√©lection du Nombre Optimal de Composantes')
            ax2.grid(True, alpha=0.3)
            
            # L√©gende combin√©e
            lines1, labels1 = ax2.get_legend_handles_labels()
            lines2, labels2 = ax2_twin.get_legend_handles_labels()
            ax2.legend(lines1 + lines2, labels1 + labels2, loc='best')
        
        plt.tight_layout()
        return fig
    
    def compare_with_kmeans(self, points_array, n_components):
        """
        Compare GMM avec K-means sur les m√™mes donn√©es.
        
        Args:
            points_array: Points √† clusterer
            n_components: Nombre de clusters/composantes
            
        Returns:
            comparison: Dictionnaire de comparaison
        """
        from sklearn.cluster import KMeans
        from sklearn.metrics import silhouette_score, calinski_harabasz_score
        
        # GMM
        gmm = GaussianMixture(n_components=n_components, 
                            covariance_type=self.covariance_type,
                            random_state=self.random_state)
        gmm_labels = gmm.fit_predict(points_array)
        
        # K-means
        kmeans = KMeans(n_clusters=n_components, random_state=self.random_state, n_init=10)
        kmeans_labels = kmeans.fit_predict(points_array)
        
        # M√©triques de comparaison
        comparison = {
            'gmm': {
                'silhouette_score': silhouette_score(points_array, gmm_labels),
                'calinski_harabasz_score': calinski_harabasz_score(points_array, gmm_labels),
                'aic': gmm.aic(points_array),
                'bic': gmm.bic(points_array),
                'log_likelihood': gmm.score(points_array)
            },
            'kmeans': {
                'silhouette_score': silhouette_score(points_array, kmeans_labels),
                'calinski_harabasz_score': calinski_harabasz_score(points_array, kmeans_labels),
                'inertia': kmeans.inertia_
            }
        }
        
        return comparison

    def get_cluster_statistics(self, gmm_analysis, n_components):
        """
        Obtient des statistiques d√©taill√©es sur un mod√®le GMM sp√©cifique.
        
        Args:
            gmm_analysis: Analyse des mod√®les GMM
            n_components: Nombre de composantes √† analyser
            
        Returns:
            statistics: Statistiques d√©taill√©es
        """
        if n_components not in gmm_analysis:
            return None
        
        analysis = gmm_analysis[n_components]
        
        statistics = {
            'model_selection': {
                'aic': analysis['aic'],
                'bic': analysis['bic'],
                'log_likelihood': analysis['log_likelihood'],
                'converged': analysis['converged'],
                'iterations': analysis['n_iter']
            },
            'clusters': []
        }
        
        # Statistiques par cluster
        for i in range(n_components):
            cluster_mask = analysis['labels'] == i
            cluster_points = np.sum(cluster_mask)
            cluster_weight = analysis['weights'][i]
            
            cluster_stats = {
                'cluster_id': i + 1,
                'n_points': int(cluster_points),
                'weight': float(cluster_weight),
                'center': analysis['centers'][i][:2],  # x, y seulement
                'coverage_contribution': float(cluster_points * cluster_weight)
            }
            
            if self.covariance_type == 'diag':
                cluster_stats['std_x'] = float(np.sqrt(analysis['covariances'][i][0]))
                cluster_stats['std_y'] = float(np.sqrt(analysis['covariances'][i][1]))
            
            statistics['clusters'].append(cluster_stats)
        
        return statistics
